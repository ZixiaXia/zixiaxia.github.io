<!doctype html>
<html lang="en">
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Zixia Xia</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- New GA4 tracking code, see https://support.google.com/analytics/answer/10271001#analyticsjs-enable-basic --> 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GNJD50R0Z7"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-GNJD50R0Z7');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>

    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
      .social-row {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
      }
      .div-1 {
        background-color: #EBEBEB;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <img src="research/selfie.jpg" height="187" width="250" alt="Zixia Xia"></h3>
        <h1>Zixia Xia</h1>
        <!-- <div class="social-row">
          <a href="mailto:xiazixia@tju.edu.cn" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a><br>
          <a href="https://github.com/ZixiaXia"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
          <a href="https://www.linkedin.com/in/zixia-xia-675614242/" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a><br>
          <br>
        </div> -->

      <h3><a href="https://ZixiaXia.github.io/">Home</a></h3>
      <h3><a href="https://ZixiaXia.github.io/research/CV.pdf">CV</a></h3>  
      <h3><a href="mailto:xiazixia@tju.edu.cn">Email</a></h3>
      <h3><a href="https://github.com/ZixiaXia">GitHub</a></h3>     
      <h3><a href="https://www.linkedin.com/in/zixia-xia-675614242/">LinkedIn</a></h3>     
      <br>

    <!-- <p><b>Contact:</b><br>Department of Economics<br>University of Oklahoma<br>322 CCD1, 308 Cate Center Drive<br>Norman, OK 73072</p> -->
    <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </header>
      <section>
      <p>I am currently a master student of computer science at the <a href="http://www.tju.edu.cn/">Tianjin University</a>.</p>
      <p>My research interests include machine learning, 3D vision, image processing, and image recognition.</p>

      <hr>
      <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>EDUCATION</h2>
      <p><b>Master Student</b><br>Department of Computer Science and Technology, Tianjin University<br>Sep 2020 - Now</p>
      <p><b>Bachelor Degree of Engineering</b><br>Department of Software Engineering, Tianjin University<br>Sep 2016 - Jun 2020</p>
      
      <hr>
      <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>WORK EXPERIENCES</h2>
      <p><b>Microsoft</b><br>Software Engineer Intern<br>Summer/2022</p>
      <p><b>China Automotive Technology and Research Center</b><br>Research Intern<br>Summer/2019</p>

      <hr>
      <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>PUBLICATIONS</h2>
      <p><b>Structure-aware dehazing of sewer inspection images based on monocular depth cues</b><br> 2021 - Jan 2022<br>
        <a href="https://ZixiaXia.github.io/research/Structure-aware dehazing of sewer inspection images based on monocular depth cues.pdf">paper</a>
        <a href="https://github.com/ZixiaXia/SANL-Net">code</a><br>
        <br>During automated inspection of sewers, hazy sewer images affects the performance of succeed vision tasks. The main challenge for either depth estimation or image dehazing is steep depth change and extensive similar texture regions in the sewer image.<br>
        <br>by works in camera calibration, autonomous driving and semantic line detection, this project aims to provide a sewer dataset including clean sewer images and sewer depth maps, and then propose a dehazing network specially for sewer images. As for depth estimation, <b>camera calibration</b> and <b>monocular cues</b> (e.g. two waterâ€“pipewall borderlines, a vanishing point) were used to calculate depth contours and generate depth maps. Then depth maps and original clean images were combined by atmospheric scattering model to synthesize various hazy images. As for image dehazing, a structure-aware non-local network (SANL-Net) was designed to leverages <b>high-level semantic information</b> and <b>low-level spatial information</b>, including three parts: a Semantic Net predicting two water borderlines, a Spatial Net calculating the residual map, and a structure-aware non-local network (SANL) module fusing features between two subnetworks.<br>
        <br>SANL-Net showed its superiority over other state-of-the-art methods with 147 in mean square error (MSE), 27.28 in peak signal to noise ratio (PSNR), 0.8963 in structural similarity index measure (SSIM), and 15.47M in parameters. And with processing by this network, real hazy sewer images also obtained higher recall and precision in deficit detection, which demonstrates effectiveness of depth estimation and image dehazing both.
        <br><img src="research/scheme.png" height="250" width="250" alt="scheme"></h3>
        <img src="research/SANL-Net.png" height="250" width="500" alt="SANL-Net"></h3>
      </p>
      <p><b>Domain-adaptive object detection with dehazing module</b><br>May 2022 - Now<br>
        <br>Most popular object localization algorithms perform terribly in hazy scenes. To solve this problem, there are two main bottlenecks: image enhancement simply optimized by existing metrics (e.g. PSNR, SSIM) could hardly guarantee definitely-improved localization results, and fixed processing pipeline could not work both in hazy and clean scenes.<br> 
        <br>So this work proposes a DefogDA-FasterRCNN network, comprising of a dehaze net, a Faster-RCNN and a domain-adaptation module. <b>Trained Faster-RCNN</b> participated in training the dehazing net, optimizing image quality and localization precision meanwhile. <b>Domain-adaptation</b> module utilized instance-level and pixel-level domain classifier to implement consistency regularization, generalizing the model to both hazy and clean scenes.<br> 
        <br>DefogDA-FasterRCNN gained strong performance on two kinds of datasets (CitySpace and Foggy CitySpace) meanwhile, and achieved higher mAP (49.51% on CitySpace and 41.01% on Foggy CitySpace) than other methods.
        <br><img src="research/DA.jpg" height="250" width="500" alt="DA"></h3>
      </p>
      <p><b>A software for automatic defect detection in sewers</b><br>Feb 2022 - Jul 2022<br>
        <a href="research/PipeInspection.mp4">video</a><br>
        <br><img src="research/PipeInspection.png" height="250" width="500" alt="DA"></h3>
      </p>


      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
